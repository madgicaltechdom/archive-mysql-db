{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a8e0b0-a26f-4cdf-8feb-8ccec8e25942",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Replace these placeholders with your Azure Blob Storage details\n",
    "storage_account_name = \"rezoarchives\"\n",
    "container_name = \"rezoarchivecontainer\"\n",
    "access_key = \"my_access_key\"\n",
    "spark.conf.set('fs.azure.account.key.' + storage_account_name + '.blob.core.windows.net', access_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "780e9bbe-31e7-4b15-9e46-0520e1d9fad9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------+----------+--------------------+--------------------+---------+----+----------+\n",
      "| id|         created_at|counter|model_name|             request|            response|   engine|lang|other_prop|\n",
      "+---+-------------------+-------+----------+--------------------+--------------------+---------+----+----------+\n",
      "|  4|2023-07-17 00:00:00|      1|   model_4|140d4910aef5b888c...|[54 2C CE D6 12 A...| engine_4|  es|    prop_4|\n",
      "|  9|2023-07-24 00:00:00|      1|   model_9|4721d370ead5db64a...|[6E 76 E1 B6 F6 6...| engine_9|  fr|    prop_9|\n",
      "| 12|2023-07-19 00:00:00|      1|  model_12|35aefbf4ac56af076...|[48 D5 6A D0 D1 B...|engine_12|  fr|   prop_12|\n",
      "| 15|2023-07-22 00:00:00|      1|  model_15|9ba585c8c054d0db7...|[56 40 EE BC 27 B...|engine_15|  es|   prop_15|\n",
      "| 17|2023-07-04 00:00:00|      1|  model_17|2751bfbd8d58aad8c...|[0B 7A 54 9A CB 3...|engine_17|  fr|   prop_17|\n",
      "| 22|2023-07-08 00:00:00|      1|  model_22|f29505e7bae07bf6a...|[2C 96 FD FA 6A F...|engine_22|  fr|   prop_22|\n",
      "| 25|2023-07-08 00:00:00|      1|  model_25|0e9d856eb1005606c...|[2A 7A 10 98 31 B...|engine_25|  es|   prop_25|\n",
      "| 31|2023-07-19 00:00:00|      1|  model_31|3b45eb49b1cf5af74...|[C2 3E C9 36 FB D...|engine_31|  de|   prop_31|\n",
      "| 36|2023-07-03 00:00:00|      1|  model_36|4c87ec9cfe431ef9c...|[E1 F0 27 1E F0 0...|engine_36|  fr|   prop_36|\n",
      "| 40|2023-07-14 00:00:00|      1|  model_40|c6ef70366dd76e2c6...|[39 36 BE 01 BF 3...|engine_40|  en|   prop_40|\n",
      "+---+-------------------+-------+----------+--------------------+--------------------+---------+----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath = \"wasbs://\" + container_name + \"@\" + storage_account_name + \".blob.core.windows.net/m202307.parquet\"\n",
    "df = spark.read.format(\"parquet\").load(filePath, inferSchema = True, header = True)\n",
    "\n",
    "# Show the top 10 rows of the Parquet data\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19ddf067-23aa-4b70-83d4-03cabdc122bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create temporary table view\n",
    "df.createOrReplaceTempView(\"m202307\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e153ac9-e471-498a-bcc6-c8a41dfc5334",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------+----------+--------------------+--------------------+--------+----+----------+\n",
      "| id|         created_at|counter|model_name|             request|            response|  engine|lang|other_prop|\n",
      "+---+-------------------+-------+----------+--------------------+--------------------+--------+----+----------+\n",
      "|  9|2023-07-24 00:00:00|      1|   model_9|4721d370ead5db64a...|[6E 76 E1 B6 F6 6...|engine_9|  fr|    prop_9|\n",
      "+---+-------------------+-------+----------+--------------------+--------------------+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query data via sql\n",
    "query_result = spark.sql(\"SELECT * FROM m202307 WHERE model_name = 'model_9'\")\n",
    "query_result.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Rezo Retrieve Parquet Format",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
